{"ast":null,"code":"// src/utils/Gemini.js\n\nexport const sendMsgToAI = async (chatHistory, imageInput, onChunkCallback) => {\n  const API_KEY = process.env.REACT_APP_GEMINI_KEY;\n  const API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:streamGenerateContent?alt=sse&key=${API_KEY}`;\n  const systemPrompt = `\n  You are \"AgroAssist,\" an expert agricultural assistant for farmers, knowledgeable about common crops, seasons, and growing conditions, especially in India.\n  Your job is to answer questions related to agriculture ONLY. If an image is provided, focus your response on analyzing the image in an agricultural context (e.g., identifying plants, diseases, pests).\n\n  --- YOUR PRIMARY RULE ---\n  1. Read the user's question and look at any provided image.\n  2. Decide if the request is related to agriculture.\n  3. IF NOT related to agriculture, respond ONLY with: \"I am only programmed to answer queries regarding agriculture and that only alone.\"\n\n  --- IF THE QUESTION IS ABOUT AGRICULTURE, FOLLOW THESE RULES ---\n\n  1. **IMAGE ANALYSIS FIRST:** If an image is provided, prioritize analyzing it based on the text prompt. Describe what you see relevant to farming (plant type, disease symptoms, pest identification, soil appearance, etc.).\n  \n  2. **CHECK FEASIBILITY (If no image or image analysis doesn't answer):**\n     - Before giving advice or asking for details, check if the text request is feasible (e.g., wrong season).\n     - If clearly unsuitable, your response MUST politely correct them and state the correct context (e.g., season). DO NOT ask follow-up questions in this case.\n\n  3. **ASK FOR DETAILS IF NEEDED (and Feasible):**\n     - If the request is feasible, image analysis is done (or no image), but you still lack details (location, soil type/pH, etc.) for a *specific text-based* recommendation, your response MUST be ONLY the question(s) asking for that info. Use a concise numbered list if multiple questions. DO NOT add introductions or other text.\n\n  4. **PROVIDE ANSWER:** If feasible and details sufficient, provide the answer.\n\n  5. **LANGUAGE RULE:** Respond in the exact same language as the User's text question.\n  6. **Format:** Use Markdown (paragraphs, *, 1.).\n  7. **Simplicity:** Use simple language, no jargon.\n  8. **Brevity:** Keep answers brief unless asking questions or providing detailed image analysis.\n  `;\n\n  // --- Map history to Gemini format ---\n  const contents = chatHistory.map(msg => {\n    const parts = [{\n      text: msg.text\n    }];\n    // If the user message had an image in history (for context), add it\n    // NOTE: This assumes msg.image stored the Base64 data which might not be ideal for history.\n    // A better approach for history might be to only send the *current* image, not past ones.\n    // For simplicity now, we only send the *new* imageInput below, not historical ones.\n    return {\n      role: msg.isBot ? \"model\" : \"user\",\n      parts: parts\n    };\n  });\n\n  // --- Add the *current* image to the *last* user message parts if it exists ---\n  if (imageInput && contents.length > 0 && contents[contents.length - 1].role === 'user') {\n    contents[contents.length - 1].parts.push({\n      inline_data: imageInput.inlineData // Use the structured image data\n    });\n  } else if (imageInput && contents.length === 0) {\n    // Handle case where image is sent with the very first message\n    contents.push({\n      role: 'user',\n      parts: [{\n        text: \"\"\n      },\n      // Add empty text part if needed by API\n      {\n        inline_data: imageInput.inlineData\n      }]\n    });\n  }\n  const requestOptions = {\n    method: \"POST\",\n    headers: {\n      \"Content-Type\": \"application/json\"\n    },\n    body: JSON.stringify({\n      contents: contents,\n      // Send history potentially including the latest image\n      systemInstruction: {\n        parts: [{\n          text: systemPrompt\n        }]\n      }\n      // Consider adding safetySettings if needed\n    })\n  };\n\n  try {\n    // Streaming Fetch Logic (remains the same)\n    const response = await fetch(API_URL, requestOptions);\n    if (!response.ok) {\n      var _errorData$error;\n      const errorData = await response.json();\n      console.error(\"Gemini API Error Response:\", errorData);\n      throw new Error(`API request failed with status ${response.status}: ${(errorData === null || errorData === void 0 ? void 0 : (_errorData$error = errorData.error) === null || _errorData$error === void 0 ? void 0 : _errorData$error.message) || 'Unknown error'}`);\n    }\n    const reader = response.body.getReader();\n    const decoder = new TextDecoder();\n    let aggregatedText = \"\";\n    while (true) {\n      const {\n        value,\n        done\n      } = await reader.read();\n      if (done) break;\n      aggregatedText += decoder.decode(value, {\n        stream: true\n      });\n      let jsonParts = aggregatedText.split('\\n');\n      aggregatedText = jsonParts.pop();\n      for (const part of jsonParts) {\n        if (part.startsWith('data: ')) {\n          try {\n            var _json$candidates, _json$candidates$, _json$candidates$$con, _json$candidates$$con2, _json$candidates$$con3;\n            const json = JSON.parse(part.substring(6));\n            if (json !== null && json !== void 0 && (_json$candidates = json.candidates) !== null && _json$candidates !== void 0 && (_json$candidates$ = _json$candidates[0]) !== null && _json$candidates$ !== void 0 && (_json$candidates$$con = _json$candidates$.content) !== null && _json$candidates$$con !== void 0 && (_json$candidates$$con2 = _json$candidates$$con.parts) !== null && _json$candidates$$con2 !== void 0 && (_json$candidates$$con3 = _json$candidates$$con2[0]) !== null && _json$candidates$$con3 !== void 0 && _json$candidates$$con3.text) {\n              const textChunk = json.candidates[0].content.parts[0].text;\n              onChunkCallback(textChunk);\n            }\n          } catch (e) {\n            console.warn(\"Could not parse stream chunk:\", part);\n          }\n        }\n      }\n    }\n  } catch (error) {\n    console.error(\"Gemini API call failed:\", error);\n    onChunkCallback(`\\n\\n--- Error connecting to Gemini API: ${error.message} ---`);\n  }\n};","map":{"version":3,"names":["sendMsgToAI","chatHistory","imageInput","onChunkCallback","API_KEY","process","env","REACT_APP_GEMINI_KEY","API_URL","systemPrompt","contents","map","msg","parts","text","role","isBot","length","push","inline_data","inlineData","requestOptions","method","headers","body","JSON","stringify","systemInstruction","response","fetch","ok","_errorData$error","errorData","json","console","error","Error","status","message","reader","getReader","decoder","TextDecoder","aggregatedText","value","done","read","decode","stream","jsonParts","split","pop","part","startsWith","_json$candidates","_json$candidates$","_json$candidates$$con","_json$candidates$$con2","_json$candidates$$con3","parse","substring","candidates","content","textChunk","e","warn"],"sources":["C:/Users/Akshay/Downloads/test/agroAssist/frontend/src/utils/Gemini.js"],"sourcesContent":["// src/utils/Gemini.js\r\n\r\nexport const sendMsgToAI = async (chatHistory, imageInput, onChunkCallback) => {\r\n  const API_KEY = process.env.REACT_APP_GEMINI_KEY;\r\n  const API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:streamGenerateContent?alt=sse&key=${API_KEY}`;\r\n\r\n  const systemPrompt = `\r\n  You are \"AgroAssist,\" an expert agricultural assistant for farmers, knowledgeable about common crops, seasons, and growing conditions, especially in India.\r\n  Your job is to answer questions related to agriculture ONLY. If an image is provided, focus your response on analyzing the image in an agricultural context (e.g., identifying plants, diseases, pests).\r\n\r\n  --- YOUR PRIMARY RULE ---\r\n  1. Read the user's question and look at any provided image.\r\n  2. Decide if the request is related to agriculture.\r\n  3. IF NOT related to agriculture, respond ONLY with: \"I am only programmed to answer queries regarding agriculture and that only alone.\"\r\n\r\n  --- IF THE QUESTION IS ABOUT AGRICULTURE, FOLLOW THESE RULES ---\r\n\r\n  1. **IMAGE ANALYSIS FIRST:** If an image is provided, prioritize analyzing it based on the text prompt. Describe what you see relevant to farming (plant type, disease symptoms, pest identification, soil appearance, etc.).\r\n  \r\n  2. **CHECK FEASIBILITY (If no image or image analysis doesn't answer):**\r\n     - Before giving advice or asking for details, check if the text request is feasible (e.g., wrong season).\r\n     - If clearly unsuitable, your response MUST politely correct them and state the correct context (e.g., season). DO NOT ask follow-up questions in this case.\r\n\r\n  3. **ASK FOR DETAILS IF NEEDED (and Feasible):**\r\n     - If the request is feasible, image analysis is done (or no image), but you still lack details (location, soil type/pH, etc.) for a *specific text-based* recommendation, your response MUST be ONLY the question(s) asking for that info. Use a concise numbered list if multiple questions. DO NOT add introductions or other text.\r\n\r\n  4. **PROVIDE ANSWER:** If feasible and details sufficient, provide the answer.\r\n\r\n  5. **LANGUAGE RULE:** Respond in the exact same language as the User's text question.\r\n  6. **Format:** Use Markdown (paragraphs, *, 1.).\r\n  7. **Simplicity:** Use simple language, no jargon.\r\n  8. **Brevity:** Keep answers brief unless asking questions or providing detailed image analysis.\r\n  `;\r\n\r\n  // --- Map history to Gemini format ---\r\n  const contents = chatHistory.map(msg => {\r\n    const parts = [{ text: msg.text }];\r\n    // If the user message had an image in history (for context), add it\r\n    // NOTE: This assumes msg.image stored the Base64 data which might not be ideal for history.\r\n    // A better approach for history might be to only send the *current* image, not past ones.\r\n    // For simplicity now, we only send the *new* imageInput below, not historical ones.\r\n    return {\r\n      role: msg.isBot ? \"model\" : \"user\",\r\n      parts: parts\r\n    };\r\n  });\r\n\r\n  // --- Add the *current* image to the *last* user message parts if it exists ---\r\n  if (imageInput && contents.length > 0 && contents[contents.length - 1].role === 'user') {\r\n    contents[contents.length - 1].parts.push({\r\n      inline_data: imageInput.inlineData // Use the structured image data\r\n    });\r\n  } else if (imageInput && contents.length === 0) {\r\n      // Handle case where image is sent with the very first message\r\n      contents.push({\r\n          role: 'user',\r\n          parts: [\r\n              { text: \"\" }, // Add empty text part if needed by API\r\n              { inline_data: imageInput.inlineData }\r\n          ]\r\n      });\r\n  }\r\n\r\n\r\n  const requestOptions = {\r\n    method: \"POST\",\r\n    headers: {\r\n      \"Content-Type\": \"application/json\",\r\n    },\r\n    body: JSON.stringify({\r\n      contents: contents, // Send history potentially including the latest image\r\n      systemInstruction: {\r\n        parts: [{ text: systemPrompt }]\r\n      }\r\n      // Consider adding safetySettings if needed\r\n    }),\r\n  };\r\n\r\n  try {\r\n    // Streaming Fetch Logic (remains the same)\r\n    const response = await fetch(API_URL, requestOptions);\r\n    if (!response.ok) {\r\n      const errorData = await response.json();\r\n      console.error(\"Gemini API Error Response:\", errorData);\r\n      throw new Error(`API request failed with status ${response.status}: ${errorData?.error?.message || 'Unknown error'}`);\r\n    }\r\n\r\n    const reader = response.body.getReader();\r\n    const decoder = new TextDecoder();\r\n    let aggregatedText = \"\";\r\n\r\n    while (true) {\r\n      const { value, done } = await reader.read();\r\n      if (done) break;\r\n\r\n      aggregatedText += decoder.decode(value, { stream: true });\r\n      let jsonParts = aggregatedText.split('\\n');\r\n      aggregatedText = jsonParts.pop();\r\n\r\n      for (const part of jsonParts) {\r\n        if (part.startsWith('data: ')) {\r\n          try {\r\n            const json = JSON.parse(part.substring(6));\r\n            if (json?.candidates?.[0]?.content?.parts?.[0]?.text) {\r\n              const textChunk = json.candidates[0].content.parts[0].text;\r\n              onChunkCallback(textChunk);\r\n            }\r\n          } catch (e) {\r\n             console.warn(\"Could not parse stream chunk:\", part);\r\n          }\r\n        }\r\n      }\r\n    }\r\n  } catch (error) {\r\n    console.error(\"Gemini API call failed:\", error);\r\n    onChunkCallback(`\\n\\n--- Error connecting to Gemini API: ${error.message} ---`);\r\n  }\r\n};"],"mappings":"AAAA;;AAEA,OAAO,MAAMA,WAAW,GAAG,MAAAA,CAAOC,WAAW,EAAEC,UAAU,EAAEC,eAAe,KAAK;EAC7E,MAAMC,OAAO,GAAGC,OAAO,CAACC,GAAG,CAACC,oBAAoB;EAChD,MAAMC,OAAO,GAAI,8GAA6GJ,OAAQ,EAAC;EAEvI,MAAMK,YAAY,GAAI;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;EAED;EACA,MAAMC,QAAQ,GAAGT,WAAW,CAACU,GAAG,CAACC,GAAG,IAAI;IACtC,MAAMC,KAAK,GAAG,CAAC;MAAEC,IAAI,EAAEF,GAAG,CAACE;IAAK,CAAC,CAAC;IAClC;IACA;IACA;IACA;IACA,OAAO;MACLC,IAAI,EAAEH,GAAG,CAACI,KAAK,GAAG,OAAO,GAAG,MAAM;MAClCH,KAAK,EAAEA;IACT,CAAC;EACH,CAAC,CAAC;;EAEF;EACA,IAAIX,UAAU,IAAIQ,QAAQ,CAACO,MAAM,GAAG,CAAC,IAAIP,QAAQ,CAACA,QAAQ,CAACO,MAAM,GAAG,CAAC,CAAC,CAACF,IAAI,KAAK,MAAM,EAAE;IACtFL,QAAQ,CAACA,QAAQ,CAACO,MAAM,GAAG,CAAC,CAAC,CAACJ,KAAK,CAACK,IAAI,CAAC;MACvCC,WAAW,EAAEjB,UAAU,CAACkB,UAAU,CAAC;IACrC,CAAC,CAAC;EACJ,CAAC,MAAM,IAAIlB,UAAU,IAAIQ,QAAQ,CAACO,MAAM,KAAK,CAAC,EAAE;IAC5C;IACAP,QAAQ,CAACQ,IAAI,CAAC;MACVH,IAAI,EAAE,MAAM;MACZF,KAAK,EAAE,CACH;QAAEC,IAAI,EAAE;MAAG,CAAC;MAAE;MACd;QAAEK,WAAW,EAAEjB,UAAU,CAACkB;MAAW,CAAC;IAE9C,CAAC,CAAC;EACN;EAGA,MAAMC,cAAc,GAAG;IACrBC,MAAM,EAAE,MAAM;IACdC,OAAO,EAAE;MACP,cAAc,EAAE;IAClB,CAAC;IACDC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;MACnBhB,QAAQ,EAAEA,QAAQ;MAAE;MACpBiB,iBAAiB,EAAE;QACjBd,KAAK,EAAE,CAAC;UAAEC,IAAI,EAAEL;QAAa,CAAC;MAChC;MACA;IACF,CAAC;EACH,CAAC;;EAED,IAAI;IACF;IACA,MAAMmB,QAAQ,GAAG,MAAMC,KAAK,CAACrB,OAAO,EAAEa,cAAc,CAAC;IACrD,IAAI,CAACO,QAAQ,CAACE,EAAE,EAAE;MAAA,IAAAC,gBAAA;MAChB,MAAMC,SAAS,GAAG,MAAMJ,QAAQ,CAACK,IAAI,CAAC,CAAC;MACvCC,OAAO,CAACC,KAAK,CAAC,4BAA4B,EAAEH,SAAS,CAAC;MACtD,MAAM,IAAII,KAAK,CAAE,kCAAiCR,QAAQ,CAACS,MAAO,KAAI,CAAAL,SAAS,aAATA,SAAS,wBAAAD,gBAAA,GAATC,SAAS,CAAEG,KAAK,cAAAJ,gBAAA,uBAAhBA,gBAAA,CAAkBO,OAAO,KAAI,eAAgB,EAAC,CAAC;IACvH;IAEA,MAAMC,MAAM,GAAGX,QAAQ,CAACJ,IAAI,CAACgB,SAAS,CAAC,CAAC;IACxC,MAAMC,OAAO,GAAG,IAAIC,WAAW,CAAC,CAAC;IACjC,IAAIC,cAAc,GAAG,EAAE;IAEvB,OAAO,IAAI,EAAE;MACX,MAAM;QAAEC,KAAK;QAAEC;MAAK,CAAC,GAAG,MAAMN,MAAM,CAACO,IAAI,CAAC,CAAC;MAC3C,IAAID,IAAI,EAAE;MAEVF,cAAc,IAAIF,OAAO,CAACM,MAAM,CAACH,KAAK,EAAE;QAAEI,MAAM,EAAE;MAAK,CAAC,CAAC;MACzD,IAAIC,SAAS,GAAGN,cAAc,CAACO,KAAK,CAAC,IAAI,CAAC;MAC1CP,cAAc,GAAGM,SAAS,CAACE,GAAG,CAAC,CAAC;MAEhC,KAAK,MAAMC,IAAI,IAAIH,SAAS,EAAE;QAC5B,IAAIG,IAAI,CAACC,UAAU,CAAC,QAAQ,CAAC,EAAE;UAC7B,IAAI;YAAA,IAAAC,gBAAA,EAAAC,iBAAA,EAAAC,qBAAA,EAAAC,sBAAA,EAAAC,sBAAA;YACF,MAAMzB,IAAI,GAAGR,IAAI,CAACkC,KAAK,CAACP,IAAI,CAACQ,SAAS,CAAC,CAAC,CAAC,CAAC;YAC1C,IAAI3B,IAAI,aAAJA,IAAI,gBAAAqB,gBAAA,GAAJrB,IAAI,CAAE4B,UAAU,cAAAP,gBAAA,gBAAAC,iBAAA,GAAhBD,gBAAA,CAAmB,CAAC,CAAC,cAAAC,iBAAA,gBAAAC,qBAAA,GAArBD,iBAAA,CAAuBO,OAAO,cAAAN,qBAAA,gBAAAC,sBAAA,GAA9BD,qBAAA,CAAgC3C,KAAK,cAAA4C,sBAAA,gBAAAC,sBAAA,GAArCD,sBAAA,CAAwC,CAAC,CAAC,cAAAC,sBAAA,eAA1CA,sBAAA,CAA4C5C,IAAI,EAAE;cACpD,MAAMiD,SAAS,GAAG9B,IAAI,CAAC4B,UAAU,CAAC,CAAC,CAAC,CAACC,OAAO,CAACjD,KAAK,CAAC,CAAC,CAAC,CAACC,IAAI;cAC1DX,eAAe,CAAC4D,SAAS,CAAC;YAC5B;UACF,CAAC,CAAC,OAAOC,CAAC,EAAE;YACT9B,OAAO,CAAC+B,IAAI,CAAC,+BAA+B,EAAEb,IAAI,CAAC;UACtD;QACF;MACF;IACF;EACF,CAAC,CAAC,OAAOjB,KAAK,EAAE;IACdD,OAAO,CAACC,KAAK,CAAC,yBAAyB,EAAEA,KAAK,CAAC;IAC/ChC,eAAe,CAAE,2CAA0CgC,KAAK,CAACG,OAAQ,MAAK,CAAC;EACjF;AACF,CAAC"},"metadata":{},"sourceType":"module","externalDependencies":[]}